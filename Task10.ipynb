{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "class ModelHMM(object):\n",
    "    def __init__(self, num_components=8, num_iter=1000):\n",
    "        self.n_components = num_components\n",
    "        self.n_iter = num_iter\n",
    "    # Define the covariance type and the type of HMM:\n",
    "        self.cov_type = 'diag'\n",
    "        self.model_name = 'GaussianHMM'\n",
    "    # Initialize the variable in which we will store the models for each word:\n",
    "        self.models = []\n",
    "    # Define the model using the specified parameters:\n",
    "        self.model = hmm.GaussianHMM(n_components=self.n_components,\n",
    "                covariance_type=self.cov_type,n_iter=self.n_iter)\n",
    "\n",
    "    # Define a method to train the model\n",
    "    # 'training_data' is a 2D numpy array where each row has length of number of mfcc coefficients\n",
    "    def train(self, training_data):\n",
    "        np.seterr(all='ignore')\n",
    "        cur_model = self.model.fit(training_data)\n",
    "        self.models.append(cur_model)\n",
    "\n",
    "    # Define a method to compute log likelihood score for input features\n",
    "    def compute_score(self, input_data):\n",
    "        return self.model.score(input_data)  # model.score returns log likelihood of sample input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_leading_silence(sound, silence_threshold=-50.0, chunk_size=10):\n",
    "    '''\n",
    "    sound is a pydub.AudioSegment\n",
    "    silence_threshold in dB\n",
    "    chunk_size in ms\n",
    "\n",
    "    iterate over chunks until you find the first one with sound\n",
    "    '''\n",
    "    trim_ms = 0 # ms\n",
    "\n",
    "    assert chunk_size > 0 # to avoid infinite loop\n",
    "    while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold and trim_ms < len(sound):\n",
    "        trim_ms += chunk_size\n",
    "\n",
    "    return trim_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anna\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from pydub import AudioSegment\n",
    "import warnings\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "def build_one_model(input_folder, num_states, num_cep_coeff):\n",
    "    # input_folder: path to the folder containing training wav files with the word\n",
    "    # num_states: number of hidden states in HMM\n",
    "    # num_cep_coeff: number of MFCC features extracted from each time window\n",
    "    X = np.array([])  # features\n",
    "    training_files = [x for x in os.listdir(input_folder) if x.endswith('.wav')]\n",
    "    for filename in training_files:\n",
    "        # Extract the current filepath and read the file\n",
    "        filepath = os.path.join(input_folder, filename)\n",
    "        sampling_freq, signal = wavfile.read(filepath)\n",
    "        sound = AudioSegment.from_file(filepath, format=\"wav\")\n",
    "        duration = len(sound)\n",
    "\n",
    "        start_trim = detect_leading_silence(sound)\n",
    "        end_trim = detect_leading_silence(sound.reverse())\n",
    "        trimmed_sound = sound[start_trim:duration - end_trim]\n",
    "        trimmed_sound.export(\"tmp.wav\", format=\"wav\")\n",
    "        # Extract features\n",
    "        # Default values:\n",
    "        # winlen=0.025, winstep=0.01, nfft=512,\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            features_mfcc = mfcc(signal, sampling_freq, numcep=num_cep_coeff)\n",
    "\n",
    "        # Append features to the variable X\n",
    "        if len(X) == 0:\n",
    "            X = features_mfcc\n",
    "        else:\n",
    "            X = np.append(X, features_mfcc, axis=0)\n",
    "\n",
    "    # Initiate HMM model object\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "        model = ModelHMM(num_components=num_states)\n",
    "\n",
    "    # Train HMM model, calculate likelihood of the sample by the trained model\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "        model.train(X)\n",
    "        model_score = model.compute_score(X)\n",
    "\n",
    "    return model, model_score, num_cep_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 22\n",
    "num_cepstr = 10\n",
    "def build_models(input_folder):\n",
    "\n",
    "    # input_folder contains subfolders with samples of words in wav files\n",
    "\n",
    "    # Initialize the variable to store all the models\n",
    "    speech_models = []\n",
    "\n",
    "    # Parse the input directory\n",
    "    for dirname in os.listdir(input_folder):\n",
    "\n",
    "        # Get name of subfolder\n",
    "        subfolder = os.path.join(input_folder, dirname)\n",
    "\n",
    "        if not os.path.isdir(subfolder):\n",
    "            continue\n",
    "\n",
    "        # Extract label\n",
    "        label = subfolder[subfolder.rfind('/') + 1:]\n",
    "\n",
    "        # Fit model for label\n",
    "        model = build_one_model(subfolder, num_states=num_components, num_cep_coeff=num_cepstr)\n",
    "\n",
    "        # Add the model to the list\n",
    "        speech_models.append((model, label))\n",
    "\n",
    "        # Reset model variable\n",
    "        model = None\n",
    "        print(\"Fitted \"+dirname)\n",
    "    return speech_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted num0\n",
      "Fitted num1\n",
      "Fitted num2\n",
      "Fitted num3\n",
      "Fitted num4\n",
      "Fitted num5\n",
      "Fitted num6\n",
      "Fitted num7\n",
      "Fitted num8\n",
      "Fitted num9\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"./MNIST_9-25\"\n",
    "digit_models = build_models(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anna\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['saved.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(digit_models,'saved.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_models = joblib.load('saved.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.silence import split_on_silence\n",
    "\n",
    "def new_chunks(filename):\n",
    "    sound_file = AudioSegment.from_wav(filename)\n",
    "    n = 20\n",
    "    silence_len = 100        \n",
    "    thresh = -40\n",
    "    audio_chunks = split_on_silence(sound_file, min_silence_len=silence_len, silence_thresh=thresh)\n",
    "    num_signals = len(audio_chunks)\n",
    "    check1 = num_signals \n",
    "    check2 = 0\n",
    "    while num_signals != 10:\n",
    "        if num_signals > 10:\n",
    "            silence_len += n\n",
    "        else:\n",
    "            silence_len -= n\n",
    "        if n > 1:\n",
    "            n //= 2\n",
    "        audio_chunks = split_on_silence(sound_file, min_silence_len=silence_len, silence_thresh=thresh)\n",
    "        num_signals = len(audio_chunks)\n",
    "        #чтобы исключить зацикливание, когда при разнице в одну секунду определяются 9 или 11 цифр:\n",
    "        if num_signals == check2 and check2 == 11: \n",
    "            break\n",
    "        check2 = check1\n",
    "        check1 = num_signals\n",
    "    return audio_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_one_word(trained_model, test_file_path):\n",
    "    # trained_model: ModelHMM object with trained model\n",
    "    # test_file_path: path to wav file\n",
    "\n",
    "    sampling_freq, signal = wavfile.read(test_file_path)\n",
    "    num_cep_coeff = trained_model[2]\n",
    "\n",
    "    # Extract features\n",
    "    # Default values:\n",
    "    # winlen=0.025, winstep=0.01, nfilt=26, nfft=512,\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        features_mfcc = mfcc(signal, sampling_freq, numcep=num_cep_coeff)\n",
    "\n",
    "        # Calculate log likelihood\n",
    "        word_score = trained_model[0].compute_score(features_mfcc)\n",
    "    return word_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "def teln(audio_chunks):\n",
    "    tel = \"\"\n",
    "    count = 0\n",
    "    for chunk in audio_chunks:\n",
    "        count += 1\n",
    "        if count == 11: #если не смог определить 10 цифр, и пришлось брать 11\n",
    "            break\n",
    "        max_score = -float('inf')\n",
    "                # Run the current feature vector through all the HMM\n",
    "                #  models and pick the one with the highest score\n",
    "        chunk.export(\"tmp.wav\", format=\"wav\")\n",
    "        for item in speech_models:\n",
    "            model, label = item\n",
    "                    # Evaluate the score and compare against the maximum score:\n",
    "            score = score_one_word(model, \"tmp.wav\")\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                predicted_label = label\n",
    "        tel = tel + predicted_label[-1]\n",
    "    return tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"./test/6/\"\n",
    "test_files = [x for x in os.listdir(input_folder) if x.endswith('.wav')]\n",
    "tels = dict()\n",
    "for filename in test_files:\n",
    "    #разделяет номер:\n",
    "    a_ch = new_chunks(\"./test/6/\" + filename)\n",
    "    #обрабатывает его:\n",
    "    num = teln(a_ch)\n",
    "    #определяет номер файла:\n",
    "    n = int(filename[0])\n",
    "    if filename[1] != '.':\n",
    "        n = n*10 + int(filename[1])\n",
    "        if filename[2] != '.':\n",
    "            n = n*10 + int(filename[2])\n",
    "    #записывает в словарь:\n",
    "    tels[n] = num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answ.txt\", \"w\") as inf:\n",
    "    for i in range(300):\n",
    "        inf.write(str(i))\n",
    "        inf.write(\",\")\n",
    "        inf.write(tels[i])\n",
    "        inf.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
